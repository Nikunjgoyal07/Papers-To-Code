{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31153,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# GQA: Training Generalized Multi-Query Transformer Models from Multi-Head Checkpoints\n# Link to paper -> https://arxiv.org/pdf/2305.13245","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T14:22:29.146908Z","iopub.execute_input":"2025-10-15T14:22:29.147255Z","iopub.status.idle":"2025-10-15T14:22:29.152751Z","shell.execute_reply.started":"2025-10-15T14:22:29.147232Z","shell.execute_reply":"2025-10-15T14:22:29.151619Z"}},"outputs":[],"execution_count":50},{"cell_type":"code","source":"import torch\nfrom torch import nn\nimport math\n\nclass GroupedQueryAttention(nn.Module):\n    def __init__(self, d_model, n_heads, num_kv_heads):\n        \n        super().__init__()\n        assert d_model % n_heads == 0, \"d_model must be divisible by n_heads\"\n        assert n_heads % num_kv_heads == 0, \"n_heads must be divisible by num_kv_heads\"\n\n        self.d_model = d_model # sequence length\n        self.n_heads = n_heads # number of attention heads, Q heads number\n        self.num_kv_heads = num_kv_heads # number of heads of K,V\n\n        self.head_dim = d_model // n_heads\n        self.num_queries_per_kv = n_heads // num_kv_heads\n\n        self.q_proj = nn.Linear(d_model, d_model)  # B,S,d_model  //  1,128,512\n\n        self.kv_dim = num_kv_heads * self.head_dim  \n\n        self.k_proj = nn.Linear(d_model, self.kv_dim)  # quarter the size of q_matrix (1,128,128)\n        self.v_proj = nn.Linear(d_model, self.kv_dim)  # quarter the size of q_matrix (1,128,128)\n\n        self.out_proj = nn.Linear(d_model, d_model)\n\n        self.scale = math.sqrt(self.head_dim)\n\n    def forward(self, x, mask=None):\n\n        batch_size, seq_len, _ = x.shape\n\n        Q = self.q_proj(x)  # (b, s, d_model)\n        K = self.k_proj(x)  # (b, s, kv_dim) <- 80% smaller!\n        V = self.v_proj(x)  # (b, s, kv_dim) <- 80% smaller!\n\n        Q = Q.view(batch_size, seq_len, self.n_heads, self.head_dim).transpose(1, 2)\n        # (batch_size, n_heads, seq_len, head_dim)      (b,32,512,16)\n\n        K = K.view(batch_size, seq_len, self.num_kv_heads, self.head_dim).transpose(1, 2)\n        V = V.view(batch_size, seq_len, self.num_kv_heads, self.head_dim).transpose(1, 2)\n        # (batch_size, num_kv_heads, seq_len, head_dim)     (b,8,512,16)\n\n        # Repeat K and V to match the number of query heads (cheap memory operation, but massive compute saving)\n        K = K.repeat_interleave(self.num_queries_per_kv, dim=1)\n        V = V.repeat_interleave(self.num_queries_per_kv, dim=1)\n\n        \n        # now the same a standard Multi-Head Attention\n        scores = torch.matmul(Q, K.transpose(-2, -1)) / self.scale\n        \n        if mask is not None:\n            scores = scores.masked_fill(mask == 0, float('-inf'))\n        \n        attn_weights = torch.softmax(scores, dim=-1)\n        attn_output = torch.matmul(attn_weights, V)\n        \n        # Concatenate heads\n        attn_output = attn_output.transpose(1, 2).contiguous()\n        attn_output = attn_output.view(batch_size, seq_len, self.d_model)\n        \n        # Apply output projection\n        output = self.out_proj(attn_output)\n        \n        return output\n        ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T13:49:08.809379Z","iopub.execute_input":"2025-10-15T13:49:08.809677Z","iopub.status.idle":"2025-10-15T13:49:08.824322Z","shell.execute_reply.started":"2025-10-15T13:49:08.809653Z","shell.execute_reply":"2025-10-15T13:49:08.823204Z"}},"outputs":[],"execution_count":31},{"cell_type":"code","source":"batch_size = 2\nseq_len = 10\nd_model = 512\nn_heads = 32\nnum_kv_heads = 8\n\n\nx = torch.randn(batch_size, seq_len, d_model)\nx.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T13:49:11.279094Z","iopub.execute_input":"2025-10-15T13:49:11.279397Z","iopub.status.idle":"2025-10-15T13:49:11.286844Z","shell.execute_reply.started":"2025-10-15T13:49:11.279374Z","shell.execute_reply":"2025-10-15T13:49:11.285671Z"}},"outputs":[{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"torch.Size([2, 10, 512])"},"metadata":{}}],"execution_count":32},{"cell_type":"code","source":"gqa = GroupedQueryAttention(d_model=d_model, n_heads=n_heads, num_kv_heads=num_kv_heads)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T13:49:11.685883Z","iopub.execute_input":"2025-10-15T13:49:11.686197Z","iopub.status.idle":"2025-10-15T13:49:11.702449Z","shell.execute_reply.started":"2025-10-15T13:49:11.686176Z","shell.execute_reply":"2025-10-15T13:49:11.700992Z"}},"outputs":[],"execution_count":33},{"cell_type":"code","source":"gqa","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T14:00:21.902184Z","iopub.execute_input":"2025-10-15T14:00:21.902556Z","iopub.status.idle":"2025-10-15T14:00:21.913815Z","shell.execute_reply.started":"2025-10-15T14:00:21.902531Z","shell.execute_reply":"2025-10-15T14:00:21.911658Z"}},"outputs":[{"execution_count":46,"output_type":"execute_result","data":{"text/plain":"GroupedQueryAttention(\n  (q_proj): Linear(in_features=512, out_features=512, bias=True)\n  (k_proj): Linear(in_features=512, out_features=128, bias=True)\n  (v_proj): Linear(in_features=512, out_features=128, bias=True)\n  (out_proj): Linear(in_features=512, out_features=512, bias=True)\n)"},"metadata":{}}],"execution_count":46},{"cell_type":"code","source":"print(f\"Input shape: {x.shape}\")\nprint(f\"Output shape: {gqa(x).shape}\")\nprint(f\"Number of parameters in K projection: {sum(p.numel() for p in gqa.k_proj.parameters())}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T13:53:53.104483Z","iopub.execute_input":"2025-10-15T13:53:53.104843Z","iopub.status.idle":"2025-10-15T13:53:53.182113Z","shell.execute_reply.started":"2025-10-15T13:53:53.104816Z","shell.execute_reply":"2025-10-15T13:53:53.179968Z"}},"outputs":[{"name":"stdout","text":"Input shape: torch.Size([2, 10, 512])\nOutput shape: torch.Size([2, 10, 512])\nNumber of parameters in K projection: 65664\n","output_type":"stream"}],"execution_count":39},{"cell_type":"code","source":"!pip install torchsummary","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T13:54:38.335164Z","iopub.execute_input":"2025-10-15T13:54:38.335916Z","iopub.status.idle":"2025-10-15T13:54:45.823217Z","shell.execute_reply.started":"2025-10-15T13:54:38.335884Z","shell.execute_reply":"2025-10-15T13:54:45.821119Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: torchsummary in /usr/local/lib/python3.11/dist-packages (1.5.1)\n","output_type":"stream"}],"execution_count":40},{"cell_type":"code","source":"from torchsummary import summary\n\n# Suppose input has shape (seq_len, d_model)\nsummary(gqa, input_size=(128, 512))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T14:00:49.790604Z","iopub.execute_input":"2025-10-15T14:00:49.790988Z","iopub.status.idle":"2025-10-15T14:00:49.815069Z","shell.execute_reply.started":"2025-10-15T14:00:49.790963Z","shell.execute_reply":"2025-10-15T14:00:49.814043Z"}},"outputs":[{"name":"stdout","text":"----------------------------------------------------------------\n        Layer (type)               Output Shape         Param #\n================================================================\n            Linear-1             [-1, 128, 512]         262,656\n            Linear-2             [-1, 128, 128]          65,664\n            Linear-3             [-1, 128, 128]          65,664\n            Linear-4             [-1, 128, 512]         262,656\n================================================================\nTotal params: 656,640\nTrainable params: 656,640\nNon-trainable params: 0\n----------------------------------------------------------------\nInput size (MB): 0.25\nForward/backward pass size (MB): 1.25\nParams size (MB): 2.50\nEstimated Total Size (MB): 4.00\n----------------------------------------------------------------\n","output_type":"stream"}],"execution_count":48},{"cell_type":"code","source":"# Standard Multi-Head Attention -> 1,050,624 parameters\n# Grouped Query Attention -> 656,640\n\n#roughly 40% less parameters","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-15T14:03:10.200470Z","iopub.execute_input":"2025-10-15T14:03:10.200856Z","iopub.status.idle":"2025-10-15T14:03:10.206252Z","shell.execute_reply.started":"2025-10-15T14:03:10.200820Z","shell.execute_reply":"2025-10-15T14:03:10.204620Z"}},"outputs":[],"execution_count":49}]}