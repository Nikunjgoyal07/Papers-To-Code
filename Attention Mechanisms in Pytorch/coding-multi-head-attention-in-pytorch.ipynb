{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch ## torch let's us create tensors and also provides helper functions\nimport torch.nn as nn ## torch.nn gives us nn.module() and nn.Linear()\nimport torch.nn.functional as F # This gives us the softmax()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-19T12:04:53.990482Z","iopub.execute_input":"2025-07-19T12:04:53.991086Z","iopub.status.idle":"2025-07-19T12:04:59.277487Z","shell.execute_reply.started":"2025-07-19T12:04:53.991061Z","shell.execute_reply":"2025-07-19T12:04:59.276322Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"class Attention(nn.Module): \n                            \n    def __init__(self, d_model=2,  \n                 row_dim=0, \n                 col_dim=1):\n        \n        super().__init__()\n        \n        self.W_q = nn.Linear(in_features=d_model, out_features=d_model, bias=False)\n        self.W_k = nn.Linear(in_features=d_model, out_features=d_model, bias=False)\n        self.W_v = nn.Linear(in_features=d_model, out_features=d_model, bias=False)\n        \n        self.row_dim = row_dim\n        self.col_dim = col_dim\n\n    def forward(self, encodings_for_q, encodings_for_k, encodings_for_v, mask=None):\n        \n        q = self.W_q(encodings_for_q)\n        k = self.W_k(encodings_for_k)\n        v = self.W_v(encodings_for_v)\n\n        sims = torch.matmul(q, k.transpose(dim0=self.row_dim, dim1=self.col_dim))\n\n        scaled_sims = sims / torch.tensor(k.size(self.col_dim)**0.5)\n\n        if mask is not None:\n            scaled_sims = scaled_sims.masked_fill(mask=mask, value=-1e9)\n            \n        attention_percents = F.softmax(scaled_sims, dim=self.col_dim)\n\n        attention_scores = torch.matmul(attention_percents, v)\n\n        return attention_scores","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-19T12:05:48.482299Z","iopub.execute_input":"2025-07-19T12:05:48.482870Z","iopub.status.idle":"2025-07-19T12:05:48.490581Z","shell.execute_reply.started":"2025-07-19T12:05:48.482845Z","shell.execute_reply":"2025-07-19T12:05:48.489629Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"encodings_for_q = torch.tensor([[1.16, 0.23],\n                                [0.57, 1.36],\n                                [4.41, -2.16]])\n\nencodings_for_k = torch.tensor([[1.16, 0.23],\n                                [0.57, 1.36],\n                                [4.41, -2.16]])\n\nencodings_for_v = torch.tensor([[1.16, 0.23],\n                                [0.57, 1.36],\n                                [4.41, -2.16]])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-19T12:05:58.386490Z","iopub.execute_input":"2025-07-19T12:05:58.387376Z","iopub.status.idle":"2025-07-19T12:05:58.410599Z","shell.execute_reply.started":"2025-07-19T12:05:58.387326Z","shell.execute_reply":"2025-07-19T12:05:58.409538Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"torch.manual_seed(42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-19T12:06:05.544871Z","iopub.execute_input":"2025-07-19T12:06:05.545162Z","iopub.status.idle":"2025-07-19T12:06:05.557734Z","shell.execute_reply.started":"2025-07-19T12:06:05.545138Z","shell.execute_reply":"2025-07-19T12:06:05.556854Z"}},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"<torch._C.Generator at 0x7e7a53849f90>"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"attention = Attention(d_model=2,row_dim=0,col_dim=1)\nattention","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-19T12:07:36.388402Z","iopub.execute_input":"2025-07-19T12:07:36.388755Z","iopub.status.idle":"2025-07-19T12:07:36.396405Z","shell.execute_reply.started":"2025-07-19T12:07:36.388731Z","shell.execute_reply":"2025-07-19T12:07:36.395529Z"}},"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"Attention(\n  (W_q): Linear(in_features=2, out_features=2, bias=False)\n  (W_k): Linear(in_features=2, out_features=2, bias=False)\n  (W_v): Linear(in_features=2, out_features=2, bias=False)\n)"},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"attention(encodings_for_q, encodings_for_k, encodings_for_v)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-19T12:07:38.397027Z","iopub.execute_input":"2025-07-19T12:07:38.397346Z","iopub.status.idle":"2025-07-19T12:07:38.404706Z","shell.execute_reply.started":"2025-07-19T12:07:38.397312Z","shell.execute_reply":"2025-07-19T12:07:38.403808Z"}},"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"tensor([[0.6226, 0.1312],\n        [0.5522, 0.2499],\n        [0.5669, 0.2324]], grad_fn=<MmBackward0>)"},"metadata":{}}],"execution_count":12},{"cell_type":"code","source":"class MultiHearAttention(nn.Module):\n    def __init__(self,d_model=2,row_dim=0,col_dim=1,num_heads=1):\n\n        super().__init__()\n\n        self.heads = nn.ModuleList(\n            [Attention(d_model, row_dim, col_dim) \n             for _ in range(num_heads)]\n        )\n        self.col_dim = col_dim\n\n    def forward(self,encodings_for_q, encodings_for_k, encodings_for_v):\n        return torch.cat([head(encodings_for_q, \n                               encodings_for_k,\n                               encodings_for_v) \n                          for head in self.heads],dim=self.col_dim)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-19T12:11:25.696947Z","iopub.execute_input":"2025-07-19T12:11:25.697324Z","iopub.status.idle":"2025-07-19T12:11:25.703405Z","shell.execute_reply.started":"2025-07-19T12:11:25.697296Z","shell.execute_reply":"2025-07-19T12:11:25.702447Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"torch.manual_seed(42)\n\n## create an attention object\nmultiHeadAttention = MultiHearAttention(d_model=2,\n                                        row_dim=0,\n                                        col_dim=1,\n                                        num_heads=2)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-19T12:15:52.247201Z","iopub.execute_input":"2025-07-19T12:15:52.247504Z","iopub.status.idle":"2025-07-19T12:15:52.254850Z","shell.execute_reply.started":"2025-07-19T12:15:52.247481Z","shell.execute_reply":"2025-07-19T12:15:52.253891Z"}},"outputs":[],"execution_count":39},{"cell_type":"code","source":"multiHeadAttention","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-19T12:15:52.801087Z","iopub.execute_input":"2025-07-19T12:15:52.801350Z","iopub.status.idle":"2025-07-19T12:15:52.807047Z","shell.execute_reply.started":"2025-07-19T12:15:52.801332Z","shell.execute_reply":"2025-07-19T12:15:52.806328Z"}},"outputs":[{"execution_count":40,"output_type":"execute_result","data":{"text/plain":"MultiHearAttention(\n  (heads): ModuleList(\n    (0-1): 2 x Attention(\n      (W_q): Linear(in_features=2, out_features=2, bias=False)\n      (W_k): Linear(in_features=2, out_features=2, bias=False)\n      (W_v): Linear(in_features=2, out_features=2, bias=False)\n    )\n  )\n)"},"metadata":{}}],"execution_count":40},{"cell_type":"code","source":"multiHeadAttention(encodings_for_q, encodings_for_k, encodings_for_v)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-19T12:15:55.750221Z","iopub.execute_input":"2025-07-19T12:15:55.750523Z","iopub.status.idle":"2025-07-19T12:15:55.758458Z","shell.execute_reply.started":"2025-07-19T12:15:55.750502Z","shell.execute_reply":"2025-07-19T12:15:55.757578Z"}},"outputs":[{"execution_count":41,"output_type":"execute_result","data":{"text/plain":"tensor([[ 1.0100,  1.0641, -0.7081, -0.8268],\n        [ 0.2040,  0.7057, -0.7417, -0.9193],\n        [ 3.4989,  2.2427, -0.7190, -0.8447]], grad_fn=<CatBackward0>)"},"metadata":{}}],"execution_count":41},{"cell_type":"code","source":"attention(encodings_for_q, encodings_for_k, encodings_for_v)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-19T12:13:09.436656Z","iopub.execute_input":"2025-07-19T12:13:09.437008Z","iopub.status.idle":"2025-07-19T12:13:09.444541Z","shell.execute_reply.started":"2025-07-19T12:13:09.436975Z","shell.execute_reply":"2025-07-19T12:13:09.443839Z"}},"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"tensor([[0.6226, 0.1312],\n        [0.5522, 0.2499],\n        [0.5669, 0.2324]], grad_fn=<MmBackward0>)"},"metadata":{}}],"execution_count":24},{"cell_type":"code","source":"heads = nn.ModuleList(\n            [Attention(2, 0, 1) \n             for _ in range(2)]\n        )\nheads","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-19T12:16:06.054930Z","iopub.execute_input":"2025-07-19T12:16:06.055268Z","iopub.status.idle":"2025-07-19T12:16:06.062778Z","shell.execute_reply.started":"2025-07-19T12:16:06.055245Z","shell.execute_reply":"2025-07-19T12:16:06.061723Z"}},"outputs":[{"execution_count":42,"output_type":"execute_result","data":{"text/plain":"ModuleList(\n  (0-1): 2 x Attention(\n    (W_q): Linear(in_features=2, out_features=2, bias=False)\n    (W_k): Linear(in_features=2, out_features=2, bias=False)\n    (W_v): Linear(in_features=2, out_features=2, bias=False)\n  )\n)"},"metadata":{}}],"execution_count":42},{"cell_type":"code","source":"torch.cat([head(encodings_for_q, \n                               encodings_for_k,\n                               encodings_for_v) \n                          for head in heads],dim=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-19T12:16:08.407237Z","iopub.execute_input":"2025-07-19T12:16:08.408089Z","iopub.status.idle":"2025-07-19T12:16:08.415864Z","shell.execute_reply.started":"2025-07-19T12:16:08.408064Z","shell.execute_reply":"2025-07-19T12:16:08.415022Z"}},"outputs":[{"execution_count":43,"output_type":"execute_result","data":{"text/plain":"tensor([[0.6226, 0.1312, 1.0106, 0.8625],\n        [0.5522, 0.2499, 1.4153, 1.0420],\n        [0.5669, 0.2324, 0.3679, 0.5894]], grad_fn=<CatBackward0>)"},"metadata":{}}],"execution_count":43},{"cell_type":"code","source":"[head(encodings_for_q, \n                               encodings_for_k,\n                               encodings_for_v) \n                          for head in heads]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-19T12:15:26.595072Z","iopub.execute_input":"2025-07-19T12:15:26.595415Z","iopub.status.idle":"2025-07-19T12:15:26.603965Z","shell.execute_reply.started":"2025-07-19T12:15:26.595369Z","shell.execute_reply":"2025-07-19T12:15:26.603035Z"}},"outputs":[{"execution_count":37,"output_type":"execute_result","data":{"text/plain":"[tensor([[-0.6674,  0.5665],\n         [-0.5970,  1.5640],\n         [-0.7832, -0.0405]], grad_fn=<MmBackward0>),\n tensor([[ 0.7700, -0.9269],\n         [ 0.7713, -0.9210],\n         [ 0.7669, -0.8751]], grad_fn=<MmBackward0>),\n tensor([[-0.2467, -0.9469],\n         [-0.1830, -0.9897],\n         [-0.4784, -0.8523]], grad_fn=<MmBackward0>)]"},"metadata":{}}],"execution_count":37},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}