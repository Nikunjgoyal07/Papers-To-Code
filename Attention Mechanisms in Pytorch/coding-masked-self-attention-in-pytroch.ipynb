{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch ## torch let's us create tensors and also provides helper functions\nimport torch.nn as nn ## torch.nn gives us nn.module() and nn.Linear()\nimport torch.nn.functional as F # This gives us the softmax()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-19T10:16:56.560048Z","iopub.execute_input":"2025-07-19T10:16:56.560465Z","iopub.status.idle":"2025-07-19T10:17:02.966304Z","shell.execute_reply.started":"2025-07-19T10:16:56.560431Z","shell.execute_reply":"2025-07-19T10:17:02.964490Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"class MaskedSelfAttention(nn.Module): \n                            \n    def __init__(self, d_model=2,  \n                 row_dim=0, \n                 col_dim=1):\n        \n        super().__init__()\n        \n        self.W_q = nn.Linear(in_features=d_model, out_features=d_model, bias=False)\n        self.W_k = nn.Linear(in_features=d_model, out_features=d_model, bias=False)\n        self.W_v = nn.Linear(in_features=d_model, out_features=d_model, bias=False)\n        \n        self.row_dim = row_dim\n        self.col_dim = col_dim\n\n        \n    def forward(self, token_encodings, mask=None):\n\n        q = self.W_q(token_encodings)\n        k = self.W_k(token_encodings)\n        v = self.W_v(token_encodings)\n\n        sims = torch.matmul(q, k.transpose(dim0=self.row_dim, dim1=self.col_dim))\n\n        scaled_sims = sims / torch.tensor(k.size(self.col_dim)**0.5)\n\n        if mask is not None:\n            ## Here we are masking out things we don't want to pay attention to\n            ##\n            ## We replace values we wanted masked out\n            ## with a very small negative number so that the SoftMax() function\n            ## will give all masked elements an output value (or \"probability\") of 0.\n            scaled_sims = scaled_sims.masked_fill(mask=mask, value=-1e9) # I've also seen -1e20 and -9e15 used in masking\n\n        attention_percents = F.softmax(scaled_sims, dim=self.col_dim)\n\n        attention_scores = torch.matmul(attention_percents, v)\n\n        return attention_scores","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-19T10:17:02.967860Z","iopub.execute_input":"2025-07-19T10:17:02.968495Z","iopub.status.idle":"2025-07-19T10:17:02.981601Z","shell.execute_reply.started":"2025-07-19T10:17:02.968305Z","shell.execute_reply":"2025-07-19T10:17:02.980225Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"encodings_matrix = torch.tensor([[1.16, 0.23],\n                                 [0.57, 1.36],\n                                 [4.41, -2.16]])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-19T10:17:03.430882Z","iopub.execute_input":"2025-07-19T10:17:03.431193Z","iopub.status.idle":"2025-07-19T10:17:03.455969Z","shell.execute_reply.started":"2025-07-19T10:17:03.431167Z","shell.execute_reply":"2025-07-19T10:17:03.454227Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"torch.manual_seed(42)\n\n## create a masked self-attention object\nmaskedSelfAttention = MaskedSelfAttention(d_model=2,\n                               row_dim=0,\n                               col_dim=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-19T10:17:12.274032Z","iopub.execute_input":"2025-07-19T10:17:12.274348Z","iopub.status.idle":"2025-07-19T10:17:12.308790Z","shell.execute_reply.started":"2025-07-19T10:17:12.274323Z","shell.execute_reply":"2025-07-19T10:17:12.306164Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"mask = torch.tril(torch.ones(3, 3))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-19T10:17:19.835884Z","iopub.execute_input":"2025-07-19T10:17:19.836283Z","iopub.status.idle":"2025-07-19T10:17:19.852835Z","shell.execute_reply.started":"2025-07-19T10:17:19.836258Z","shell.execute_reply":"2025-07-19T10:17:19.851598Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"mask","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-19T10:17:23.146325Z","iopub.execute_input":"2025-07-19T10:17:23.146702Z","iopub.status.idle":"2025-07-19T10:17:23.231478Z","shell.execute_reply.started":"2025-07-19T10:17:23.146674Z","shell.execute_reply":"2025-07-19T10:17:23.230283Z"}},"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"tensor([[1., 0., 0.],\n        [1., 1., 0.],\n        [1., 1., 1.]])"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"mask = mask == 0","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-19T10:17:33.566054Z","iopub.execute_input":"2025-07-19T10:17:33.566455Z","iopub.status.idle":"2025-07-19T10:17:33.571765Z","shell.execute_reply.started":"2025-07-19T10:17:33.566423Z","shell.execute_reply":"2025-07-19T10:17:33.570486Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"mask","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-19T10:17:40.687205Z","iopub.execute_input":"2025-07-19T10:17:40.687565Z","iopub.status.idle":"2025-07-19T10:17:40.695434Z","shell.execute_reply.started":"2025-07-19T10:17:40.687540Z","shell.execute_reply":"2025-07-19T10:17:40.694428Z"}},"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"tensor([[False,  True,  True],\n        [False, False,  True],\n        [False, False, False]])"},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"## calculate masked self-attention\nmaskedSelfAttention(encodings_matrix, mask)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-19T10:17:49.177029Z","iopub.execute_input":"2025-07-19T10:17:49.177422Z","iopub.status.idle":"2025-07-19T10:17:49.228108Z","shell.execute_reply.started":"2025-07-19T10:17:49.177367Z","shell.execute_reply":"2025-07-19T10:17:49.226909Z"}},"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"tensor([[ 0.6038,  0.7434],\n        [-0.0062,  0.6072],\n        [ 3.4989,  2.2427]], grad_fn=<MmBackward0>)"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}