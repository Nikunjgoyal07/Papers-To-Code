{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-07-19T08:41:41.874537Z","iopub.execute_input":"2025-07-19T08:41:41.874798Z","iopub.status.idle":"2025-07-19T08:41:44.162153Z","shell.execute_reply.started":"2025-07-19T08:41:41.874778Z","shell.execute_reply":"2025-07-19T08:41:44.161243Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"import torch ## torch let's us create tensors and also provides helper functions\nimport torch.nn as nn ## torch.nn gives us nn.module() and nn.Linear()\nimport torch.nn.functional as F # This gives us the softmax()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-19T08:41:44.163780Z","iopub.execute_input":"2025-07-19T08:41:44.164224Z","iopub.status.idle":"2025-07-19T08:41:48.755110Z","shell.execute_reply.started":"2025-07-19T08:41:44.164200Z","shell.execute_reply":"2025-07-19T08:41:48.754177Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"class SelfAttention(nn.Module): \n                            \n    def __init__(self, d_model=2,  \n                 row_dim=0, \n                 col_dim=1):\n        ## d_model = the number of embedding values per token.\n        ##           Because we want to be able to do the math by hand, we've\n        ##           the default value for d_model=2.\n        ##           However, in \"Attention Is All You Need\" d_model=512\n        ##\n        ## row_dim, col_dim = the indices we should use to access rows or columns\n\n        \n        super().__init__()\n        \n        ## Initialize the Weights (W) that we'll use to create the\n        ## query (q), key (k) and value (v) for each token\n        ## NOTE: A lot of implementations include bias terms when\n        ##       creating the the queries, keys, and values, but\n        ##       the original manuscript that described Attention,\n        ##       \"Attention Is All You Need\" did not, so we won't either\n        self.W_q = nn.Linear(in_features=d_model, out_features=d_model, bias=False)\n        self.W_k = nn.Linear(in_features=d_model, out_features=d_model, bias=False)\n        self.W_v = nn.Linear(in_features=d_model, out_features=d_model, bias=False)\n        \n        self.row_dim = row_dim\n        self.col_dim = col_dim\n\n        \n    def forward(self, token_encodings):\n        ## Create the query, key and values using the encoding numbers\n        ## associated with each token (token encodings)\n        q = self.W_q(token_encodings)\n        k = self.W_k(token_encodings)\n        v = self.W_v(token_encodings)\n\n        ## Compute similarities scores: (q * k^T)\n        sims = torch.matmul(q, k.transpose(dim0=self.row_dim, dim1=self.col_dim))\n\n        ## Scale the similarities by dividing by sqrt(k.col_dim)\n        scaled_sims = sims / torch.tensor(k.size(self.col_dim)**0.5)\n\n        ## Apply softmax to determine what percent of each tokens' value to\n        ## use in the final attention values.\n        attention_percents = F.softmax(scaled_sims, dim=self.col_dim)\n\n        ## Scale the values by their associated percentages and add them up.\n        attention_scores = torch.matmul(attention_percents, v)\n\n        return attention_scores","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-19T08:56:01.705220Z","iopub.execute_input":"2025-07-19T08:56:01.705516Z","iopub.status.idle":"2025-07-19T08:56:01.713058Z","shell.execute_reply.started":"2025-07-19T08:56:01.705494Z","shell.execute_reply":"2025-07-19T08:56:01.712111Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"encodings_matrix = torch.tensor([[1.16, 0.23],\n                                 [0.57, 1.36],\n                                 [4.41, -2.16]])\n\ntorch.manual_seed(42)\n\nself_attention = SelfAttention(d_model=2,row_dim=0, col_dim=1)\n\nself_attention(encodings_matrix)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-19T09:01:26.331983Z","iopub.execute_input":"2025-07-19T09:01:26.332279Z","iopub.status.idle":"2025-07-19T09:01:26.369582Z","shell.execute_reply.started":"2025-07-19T09:01:26.332258Z","shell.execute_reply":"2025-07-19T09:01:26.368705Z"}},"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"tensor([[1.0100, 1.0641],\n        [0.2040, 0.7057],\n        [3.4989, 2.2427]], grad_fn=<MmBackward0>)"},"metadata":{}}],"execution_count":17},{"cell_type":"code","source":"results = self_attention(encodings_matrix)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-19T09:02:03.597106Z","iopub.execute_input":"2025-07-19T09:02:03.597926Z","iopub.status.idle":"2025-07-19T09:02:03.602317Z","shell.execute_reply.started":"2025-07-19T09:02:03.597904Z","shell.execute_reply":"2025-07-19T09:02:03.601480Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"print(self_attention.W_q.weight.transpose(0,1))\nprint(\"\\n\")\nprint(self_attention.W_k.weight.transpose(0, 1))\nprint(\"\\n\")\nprint(self_attention.W_v.weight.transpose(0, 1))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-19T09:05:55.693471Z","iopub.execute_input":"2025-07-19T09:05:55.693846Z","iopub.status.idle":"2025-07-19T09:05:55.701649Z","shell.execute_reply.started":"2025-07-19T09:05:55.693821Z","shell.execute_reply":"2025-07-19T09:05:55.700715Z"}},"outputs":[{"name":"stdout","text":"tensor([[ 0.5406, -0.1657],\n        [ 0.5869,  0.6496]], grad_fn=<TransposeBackward0>)\n\n\ntensor([[-0.1549, -0.3443],\n        [ 0.1427,  0.4153]], grad_fn=<TransposeBackward0>)\n\n\ntensor([[ 0.6233,  0.6146],\n        [-0.5188,  0.1323]], grad_fn=<TransposeBackward0>)\n","output_type":"stream"}],"execution_count":39},{"cell_type":"code","source":"print(self_attention.W_q(encodings_matrix))\nprint(self_attention.W_k(encodings_matrix))\nprint(self_attention.W_v(encodings_matrix))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-19T09:07:10.875136Z","iopub.execute_input":"2025-07-19T09:07:10.876011Z","iopub.status.idle":"2025-07-19T09:07:10.884166Z","shell.execute_reply.started":"2025-07-19T09:07:10.875980Z","shell.execute_reply":"2025-07-19T09:07:10.882866Z"}},"outputs":[{"name":"stdout","text":"tensor([[ 0.7621, -0.0428],\n        [ 1.1063,  0.7890],\n        [ 1.1164, -2.1336]], grad_fn=<MmBackward0>)\ntensor([[-0.1469, -0.3038],\n        [ 0.1057,  0.3685],\n        [-0.9914, -2.4152]], grad_fn=<MmBackward0>)\ntensor([[ 0.6038,  0.7434],\n        [-0.3502,  0.5303],\n        [ 3.8695,  2.4246]], grad_fn=<MmBackward0>)\n","output_type":"stream"}],"execution_count":43},{"cell_type":"code","source":"q = self_attention.W_q(encodings_matrix)\nq","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-19T09:08:38.561645Z","iopub.execute_input":"2025-07-19T09:08:38.562013Z","iopub.status.idle":"2025-07-19T09:08:38.569726Z","shell.execute_reply.started":"2025-07-19T09:08:38.561987Z","shell.execute_reply":"2025-07-19T09:08:38.568727Z"}},"outputs":[{"execution_count":51,"output_type":"execute_result","data":{"text/plain":"tensor([[ 0.7621, -0.0428],\n        [ 1.1063,  0.7890],\n        [ 1.1164, -2.1336]], grad_fn=<MmBackward0>)"},"metadata":{}}],"execution_count":51},{"cell_type":"code","source":"k = self_attention.W_k(encodings_matrix)\nk","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-19T09:08:31.864525Z","iopub.execute_input":"2025-07-19T09:08:31.864836Z","iopub.status.idle":"2025-07-19T09:08:31.872089Z","shell.execute_reply.started":"2025-07-19T09:08:31.864800Z","shell.execute_reply":"2025-07-19T09:08:31.871247Z"}},"outputs":[{"execution_count":50,"output_type":"execute_result","data":{"text/plain":"tensor([[-0.1469, -0.3038],\n        [ 0.1057,  0.3685],\n        [-0.9914, -2.4152]], grad_fn=<MmBackward0>)"},"metadata":{}}],"execution_count":50},{"cell_type":"code","source":"sims = torch.matmul(q, k.transpose(dim0=0, dim1=1))\nsims","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-19T09:08:45.403794Z","iopub.execute_input":"2025-07-19T09:08:45.404121Z","iopub.status.idle":"2025-07-19T09:08:45.411205Z","shell.execute_reply.started":"2025-07-19T09:08:45.404099Z","shell.execute_reply":"2025-07-19T09:08:45.410572Z"}},"outputs":[{"execution_count":52,"output_type":"execute_result","data":{"text/plain":"tensor([[-0.0990,  0.0648, -0.6523],\n        [-0.4022,  0.4078, -3.0024],\n        [ 0.4842, -0.6683,  4.0461]], grad_fn=<MmBackward0>)"},"metadata":{}}],"execution_count":52},{"cell_type":"code","source":"scaled_sims = sims / (torch.tensor(2)**0.5)\nscaled_sims","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-19T09:08:51.697105Z","iopub.execute_input":"2025-07-19T09:08:51.697421Z","iopub.status.idle":"2025-07-19T09:08:51.712459Z","shell.execute_reply.started":"2025-07-19T09:08:51.697396Z","shell.execute_reply":"2025-07-19T09:08:51.711672Z"}},"outputs":[{"execution_count":53,"output_type":"execute_result","data":{"text/plain":"tensor([[-0.0700,  0.0458, -0.4612],\n        [-0.2844,  0.2883, -2.1230],\n        [ 0.3424, -0.4725,  2.8610]], grad_fn=<DivBackward0>)"},"metadata":{}}],"execution_count":53},{"cell_type":"code","source":"attention_percents = F.softmax(scaled_sims, dim=1)\nattention_percents","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-19T09:08:58.587598Z","iopub.execute_input":"2025-07-19T09:08:58.587934Z","iopub.status.idle":"2025-07-19T09:08:58.595771Z","shell.execute_reply.started":"2025-07-19T09:08:58.587905Z","shell.execute_reply":"2025-07-19T09:08:58.594951Z"}},"outputs":[{"execution_count":54,"output_type":"execute_result","data":{"text/plain":"tensor([[0.3573, 0.4011, 0.2416],\n        [0.3410, 0.6047, 0.0542],\n        [0.0722, 0.0320, 0.8959]], grad_fn=<SoftmaxBackward0>)"},"metadata":{}}],"execution_count":54},{"cell_type":"code","source":"result_verify = torch.matmul(attention_percents, self_attention.W_v(encodings_matrix))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-19T09:09:43.679176Z","iopub.execute_input":"2025-07-19T09:09:43.679458Z","iopub.status.idle":"2025-07-19T09:09:43.684472Z","shell.execute_reply.started":"2025-07-19T09:09:43.679440Z","shell.execute_reply":"2025-07-19T09:09:43.683604Z"}},"outputs":[],"execution_count":57},{"cell_type":"code","source":"results","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-19T09:09:56.127056Z","iopub.execute_input":"2025-07-19T09:09:56.127646Z","iopub.status.idle":"2025-07-19T09:09:56.133996Z","shell.execute_reply.started":"2025-07-19T09:09:56.127620Z","shell.execute_reply":"2025-07-19T09:09:56.133254Z"}},"outputs":[{"execution_count":59,"output_type":"execute_result","data":{"text/plain":"tensor([[1.0100, 1.0641],\n        [0.2040, 0.7057],\n        [3.4989, 2.2427]], grad_fn=<MmBackward0>)"},"metadata":{}}],"execution_count":59},{"cell_type":"code","source":"result_verify","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-19T09:10:01.392164Z","iopub.execute_input":"2025-07-19T09:10:01.392437Z","iopub.status.idle":"2025-07-19T09:10:01.399317Z","shell.execute_reply.started":"2025-07-19T09:10:01.392418Z","shell.execute_reply":"2025-07-19T09:10:01.398518Z"}},"outputs":[{"execution_count":60,"output_type":"execute_result","data":{"text/plain":"tensor([[1.0100, 1.0641],\n        [0.2040, 0.7057],\n        [3.4989, 2.2427]], grad_fn=<MmBackward0>)"},"metadata":{}}],"execution_count":60},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}